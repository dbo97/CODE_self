{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##modules\n",
    "#%matplotlib widget\n",
    "#%matplotlib inline\n",
    "\n",
    "%matplotlib qt\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# Establecer un backend interactivo, como 'Qt5Agg', 'GTK3Agg', etc.\n",
    "# Esto depende de los backends disponibles en tu sistema.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use('Qt5Agg')  # Aseg√∫rate de que este backend est√° instalado.\n",
    "\n",
    "import pandas as pd \n",
    "import os\n",
    "import sys\n",
    "\n",
    "from mne.preprocessing import ICA, corrmap, create_ecg_epochs, create_eog_epochs\n",
    "\n",
    "from os.path import join as pathjoin\n",
    "from time import time\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from autoreject import AutoReject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables path\n",
    "layer_script = \"block\"\n",
    "\n",
    "#process=\"\"\n",
    "disco=\"g\"\n",
    "\n",
    "subj = \"sub-A2004\"\n",
    "subj_copy=subj+\"_copia\"\n",
    "\n",
    "#subj = sys.argv[1] ## name of participant list\n",
    "\n",
    "# Carpeta general\n",
    "datadir = Path(f\"{disco}:\\MOUS_204\")\n",
    "\n",
    "#carpetas generales de datos\n",
    "mri_dir = datadir / f\"{subj}\"/\"anat\"\n",
    "meg_dir = datadir / f\"{subj}\"/\"meg\"\n",
    "\n",
    "# Carpeta de preprocesado\n",
    "output_preproc = datadir / \"output_preproc\"\n",
    "\n",
    "preproc_path = output_preproc / f\"preproc_{layer_script}\"\n",
    "preproc_path.mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "# Carpeta de epocas \"sucias\"\n",
    "epochs_path = preproc_path / f\"epochs_{layer_script}\"\n",
    "epochs_path.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "# Carpeta de ICA\n",
    "ICA_path = preproc_path / f\"ICA_{layer_script}\"\n",
    "ICA_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# √âpocas limpias\n",
    "epochs_clean_path = preproc_path / f\"epochs_clean_{layer_script}\"\n",
    "epochs_clean_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#epocas evoked\n",
    "evoked_path = Path(preproc_path) / f\"evoked_{layer_script}\"\n",
    "evoked_path.mkdir(parents=True, exist_ok=True)\n",
    " \n",
    "\n",
    "# Definir la carpeta de output_source antes de usarla\n",
    "output_source = Path(r\"g:\\MOUS_204\\output_source\")\n",
    "\n",
    "source_path = output_source / f\"source_{layer_script}\"\n",
    "source_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#raw_hsp es el raw con fiducials cargados\n",
    "raw_hsp_path = source_path / f\"raw_hsp\"\n",
    "raw_hsp_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carpeta de forward solution\n",
    "fwd_path = source_path / f\"fwd\"\n",
    "fwd_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Carpeta de inverse solution\n",
    "inverse_path = source_path / f\"inverse\"\n",
    "inverse_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "#carpeta analysis\n",
    "output_analysis= datadir / \"output_analysis\"\n",
    "analysis_path = output_analysis / f\"analysis_{layer_script}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'morlet' from 'scipy.signal' (c:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\scipy\\signal\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m morlet\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'morlet' from 'scipy.signal' (c:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\scipy\\signal\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from scipy.signal import morlet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'morlet' from 'scipy.signal' (c:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\scipy\\signal\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maperiodic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirasa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_irasa\n\u001b[0;32m      4\u001b[0m mne\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mset_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUBJECTS_DIR\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mwsl$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUbuntu-20.04\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124musr\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mfreesurfer\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msubjects\u001b[39m\u001b[38;5;124m'\u001b[39m, set_env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\neurodsp\\aperiodic\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdfa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_fluctuations, compute_rescaled_range, compute_detrended_fluctuation\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautocorr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_autocorr\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirasa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_irasa, fit_irasa\n",
      "File \u001b[1;32mc:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\neurodsp\\aperiodic\\irasa.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m signal\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m curve_fit\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspectral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_spectrum, trim_spectrum\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m###################################################################################################\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m###################################################################################################\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_irasa\u001b[39m(sig, fs, f_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, thresh\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mspectrum_kwargs):\n",
      "File \u001b[1;32mc:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\neurodsp\\spectral\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Spectral module, for calculating power spectra, spectral variance, etc.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpower\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (compute_spectrum, compute_spectrum_welch,\n\u001b[0;32m      4\u001b[0m                     compute_spectrum_wavelet, compute_spectrum_medfilt)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmeasures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_absolute_power, compute_relative_power, compute_band_ratio\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvariance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_scv, compute_scv_rs, compute_spectral_hist\n",
      "File \u001b[1;32mc:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\neurodsp\\spectral\\power.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_param_options\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutliers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m discard_outliers\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtimefrequency\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwavelets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_wavelet_transform\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspectral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trim_spectrum\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspectral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_spg_settings\n",
      "File \u001b[1;32mc:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\neurodsp\\timefrequency\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Time-frequency analyse of neural time series.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhilbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m robust_hilbert, phase_by_time, amp_by_time, freq_by_time\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwavelets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute_wavelet_transform, convolve_wavelet\n",
      "File \u001b[1;32mc:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\neurodsp\\timefrequency\\wavelets.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Time-frequency decompositions using wavelets.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m morlet\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_freqs\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mneurodsp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_n_cycles, check_param_options\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'morlet' from 'scipy.signal' (c:\\Users\\UCM\\anaconda3\\Lib\\site-packages\\scipy\\signal\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "from neurodsp.aperiodic.irasa import compute_irasa\n",
    "\n",
    "mne.utils.set_config('SUBJECTS_DIR', r'\\\\wsl$\\Ubuntu-20.04\\usr\\local\\freesurfer\\subjects', set_env=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading g:\\MOUS_204\\output_preproc\\preproc_block\\evoked_block\\sub-A2004_evoked_zinnen_block-ave.fif ...\n",
      "    Reading extended channel information\n",
      "    Found the data of interest:\n",
      "        t =       0.00 ...   42000.00 ms (fix_zinnen)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 24 - aspect type = 100\n",
      "No projector specified for this dataset. Please consider the method self.add_proj.\n",
      "No baseline correction applied\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# epochs_zinnen_path = epochs_clean_path / f\"{subj}_epochs_zinnen_{type_script}\"\n",
    "# epochs_woorden_path = epochs_clean_path / f\"{subj}_epochs_woorden_{type_script}\"\n",
    "\n",
    "path_zinnen= evoked_path / f\"{subj}_evoked_zinnen_{layer_script}-ave.fif\"\n",
    "\n",
    "evokeds_zinnen = mne.read_evokeds(path_zinnen) \n",
    "\n",
    "evoked_zinnen=evokeds_zinnen[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##IGNORE THISSS\n",
    "\n",
    "# # Compute power spectrum omitting nans\n",
    "\n",
    "\n",
    "# ##power spectrum omitting nans\n",
    "# def power_spectrum_nans(epochs, fmin, fmax,nfft, missing=\"conservative\" ):\n",
    "#     #I¬¥m going to use the raw.comput_psd method as it includes a method to omit bads\n",
    "#     # transform each epoch into a raw\n",
    "    \n",
    "#     #pruebas funcion power_spectrum_nans\n",
    "#     #epochs.plot()\n",
    "#     #convierto los epochs en un array\n",
    "#     epochs_data = epochs.get_data()\n",
    "#     info=epochs.info\n",
    "#     sfreq=epochs.info['sfreq']\n",
    "#     raw_epoch_all=[]\n",
    "#     psds_all=[]\n",
    "#     epochs_rejected=[]\n",
    "#     for i in range(0,len(epochs_data)):\n",
    "#         # check if there are nans in the data\n",
    "#         if np.isnan(epochs_data[i]).any():\n",
    "#             if missing==\"conservative\":\n",
    "#                 #mark nans as bad \n",
    "#                 data = epochs_data[i]  # Sustituir data por epochs_data[6]\n",
    "\n",
    "#                 # Detectar los puntos de tiempo donde TODOS los canales tienen NaN\n",
    "#                 nans_per_timepoint = np.isnan(data).all(axis=0)\n",
    "\n",
    "#                 # Encontrar los √≠ndices donde empiezan los agrupamientos de NaNs\n",
    "#                 nan_start_indices = np.where((~nans_per_timepoint[:-1]) & (nans_per_timepoint[1:]))[0] + 1\n",
    "#                 nan_start_sec= nan_start_indices/sfreq\n",
    "\n",
    "#                 # Encontrar los √≠ndices donde terminan los agrupamientos de NaNs\n",
    "#                 nan_end_indices = np.where((nans_per_timepoint[:-1]) & (~nans_per_timepoint[1:]))[0]\n",
    "#                 nan_end_sec= nan_end_indices/sfreq\n",
    "#                 duration = nan_end_indices - nan_start_indices\n",
    "\n",
    "#                 #i do zero padding in the end so the epochs last the same, having nans or not\n",
    "#                 nan_duration = np.sum(nans_per_timepoint)\n",
    "#                 n_channels, n_times=epochs_data[i].shape\n",
    "#                 zero_padding = np.zeros((n_channels, nan_duration))\n",
    "#                 print(f\"zero padding shape: {zero_padding.shape}, len zero padding: {len(zero_padding[1])},len nans: {nan_duration}\")\n",
    "#                 data = np.hstack([data, zero_padding])\n",
    "\n",
    "#                 # Mostrar los puntos de tiempo donde empiezan y terminan los agrupamientos de NaNs\n",
    "#                 print(f\"Los agrupamientos de NaNs empiezan en los siguientes puntos de tiempo:, {nan_start_indices}, en los segundos: {nan_start_sec}\")\n",
    "#                 print(f\"Los agrupamientos de NaNs terminan en los siguientes puntos de tiempo:, {nan_end_indices}, en los segundos: {nan_end_sec}\")\n",
    "\n",
    "#                 raw_epoch= mne.io.RawArray(data,info)\n",
    "#                 raw_epoch.set_annotations(mne.Annotations(onset=nan_end_indices,duration= duration ,description='bad'))\n",
    "#                 raw_epoch_all.append(raw_epoch)\n",
    "#                 psds=raw_epoch.compute_psd(method='welch', fmin=fmin, fmax=fmax, reject_by_annotation=True, n_fft = int(6 * sfreq))\n",
    "#                 psds_all.append(psds)\n",
    "            \n",
    "#             if missing==\"drop\":\n",
    "#                 print(f\"epoca {i} contiene nans, se va a omitir\")\n",
    "#                 epochs_rejected.append(i)\n",
    "#                 continue\n",
    "            \n",
    "#         else:\n",
    "#             raw_epoch= mne.io.RawArray(epochs_data[i],info)\n",
    "#             raw_epoch_all.append(raw_epoch)\n",
    "\n",
    "#             psds=raw_epoch.compute_psd(method='welch', fmin=fmin, fmax=fmax, reject_by_annotation=True, n_fft = nfft)\n",
    "#             psds_all.append(psds)\n",
    "        \n",
    "#     return psds_all, epochs_rejected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover\">\n",
       "    <tr>\n",
       "        <th>Condition</th>\n",
       "        <td>fix_zinnen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Data kind</th>\n",
       "        <td>average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Timepoints</th>\n",
       "        <td>22801 samples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Channels</th>\n",
       "        <td>273 channels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Number of averaged epochs</th>\n",
       "        <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range (secs)</th>\n",
       "        <td>0.0 ‚Äì 38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline (secs)</th>\n",
       "        <td>off</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Evoked | 'fix_zinnen' (average, N=24), 0 ‚Äì 38 s, baseline off, 273 ch, ~47.7 MB>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evoked=evoked_zinnen.copy().crop(tmin=0, tmax=38)\n",
    "\n",
    "evoked.pick(\"meg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.707 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done   4 out of  10 | elapsed:    2.3s remaining:    3.5s\n",
      "[Parallel(n_jobs=10)]: Done   7 out of  10 | elapsed:    2.3s remaining:    0.9s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    2.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    2.3s finished\n"
     ]
    }
   ],
   "source": [
    "## obtener power spechtum de el objeto evoked\n",
    "# psds=evoked.compute_psd(method='welch', fmin=fmin, fmax=fmax, reject_by_annotation=True, n_fft = int(6 * sfreq))\n",
    "# psds_all.append(psds)\n",
    "            \n",
    "# psds,freqs= mne.time_frequency.psd_array_welch(array, sfreq, fmin=0, fmax=inf, n_fft=256, n_overlap=0, \n",
    "# #                                    n_per_seg=None, n_jobs=None, average='mean', window='hamming', remove_dc=True, *, \n",
    "# #                                    output='power', verbose=None)\n",
    "\n",
    "\n",
    "\n",
    "##please note THAT THIS IS ONLY FOR EVOKED, YOU NEED TO CALCULATE IT THROUGH EPOCHS\n",
    "\n",
    "##def compute_psd(self, fmin=0, fmax=np.inf, tmin=None, tmax=None, proj=False)\n",
    "array=evoked.get_data()\n",
    "sfreq=evoked.info['sfreq']\n",
    "fmin=0.5\n",
    "fmax=40\n",
    "nfft=1024 # to increase the spectral resolution, , although you can go to 4096 if you want to see more details\n",
    "njobs=10\n",
    "\n",
    "##compute psd FOR WHOLE SIGNAL\n",
    "psds,freqs= mne.time_frequency.psd_array_welch(array, sfreq, fmin=fmin, fmax=fmax, n_fft=nfft, n_jobs=njobs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_irasa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m fmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m273\u001b[39m):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Aplicar IRASA para separar el espectro fractal (1/f)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     freqs, psd_fractal, psd_oscil \u001b[38;5;241m=\u001b[39m compute_irasa(array[i], sfreq, f_range\u001b[38;5;241m=\u001b[39m(fmin, fmax))\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# üìå 4Ô∏è‚É£ Ajustar regresi√≥n log-log en el espectro fractal\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     log_freqs, log_psd_fractal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(freqs), np\u001b[38;5;241m.\u001b[39mlog10(psd_fractal)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_irasa' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# üìå 3Ô∏è‚É£ Calcular el PLE con IRASA\n",
    "ple_values = []  # Lista para almacenar los valores PLE\n",
    "\n",
    "\n",
    "# Obtener los datos del canal en todas las √©pocas\n",
    "#data = epochs.get_data()[:, ch_idx, :]  # (n_epochs, n_samples)\n",
    "\n",
    "fmin=0.5\n",
    "fmax=40\n",
    "\n",
    "for i in range(0,273):\n",
    "    # Aplicar IRASA para separar el espectro fractal (1/f)\n",
    "    freqs, psd_fractal, psd_oscil = compute_irasa(array[i], sfreq, f_range=(fmin, fmax))\n",
    "\n",
    "    # üìå 4Ô∏è‚É£ Ajustar regresi√≥n log-log en el espectro fractal\n",
    "    log_freqs, log_psd_fractal = np.log10(freqs), np.log10(psd_fractal)\n",
    "\n",
    "    # Ajuste lineal: log(P) = -Œ≤ log(f) + c\n",
    "    slope, intercept = np.polyfit(log_freqs, log_psd_fractal, 1)\n",
    "\n",
    "    # Guardar el exponente PLE (es el negativo de la pendiente)\n",
    "    ple_values.append(-slope)\n",
    "\n",
    "# üìå 5Ô∏è‚É£ Promediar el PLE por canal\n",
    "ple_values = np.array(ple_values)\n",
    "print(f\"Power Law Exponent (PLE) promedio por canal: {ple_values.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## compute power law exponent for each epoch\n",
    "# def ple_exponent(psds_all, isplot=False):\n",
    "#     ##prueba con epochs, ahora has de adaptarlo a la funci√≥n de power_spectrum_nans \n",
    "#     # first you need to obtain the frequencies, \n",
    "#     freqs= psds_all[0].freqs\n",
    "#     #for np.polyfit we need to convert the frequencies to array\n",
    "#     psds_array = [psds.get_data() for psds in psds_all]\n",
    "#     psds_avg = [np.mean(epoch_psd, axis=0) for epoch_psd in psds_array]\n",
    "#     psds_grand_avg = np.mean(psds_avg, axis=0)\n",
    "\n",
    "#     coeffs= np.polyfit(np.log10(freqs), np.log10(psds_grand_avg), deg=1)\n",
    "#     PLE= -coeffs[0]\n",
    "#     if isplot==True:\n",
    "#         #plot of the power spectrum\n",
    "#         plt.loglog(freqs, psds_grand_avg,  label='PSD Mean')\n",
    "#         #plot of the coeffs calculated\n",
    "#         #its 10**y, where y is the linear regression, ax+b, a is slope, x is log10(freqs) and b is the intercept\n",
    "#         y=coeffs[1] + coeffs[0]*np.log10(freqs)\n",
    "#         plt.loglog(freqs, 10**y, 'r--', label=f'Fit PLE = {PLE:.2f}')\n",
    "#         plt.xlabel('Frequency (Hz)')\n",
    "#         plt.ylabel('Power Spectral Density (dB/Hz)')\n",
    "#         plt.title('Power Law Exponent Fit using MNE-Python')\n",
    "#         plt.legend()\n",
    "#         plt.grid(True)\n",
    "#         plt.show()\n",
    "\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#     return coeffs, PLE, psds_grand_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
